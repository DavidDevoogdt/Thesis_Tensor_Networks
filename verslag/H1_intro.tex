
\section{Introduction}

In 2015, there were about 5.6 million known physics papers in literature. At the current rate, this number doubles every 18.7 years \cite{Sinatra2015}. Despite this enormous body of literature, there are a lot of things which are not completely understood. Some examples include a self-consistent theory of quantum gravity, the need for dark energy and matter in cosmology, the arrow of time, the matter-antimatter asymmetry. There even is no interpretation of quantum mechanics where everyone agrees upon \cite{Lulea2015}.
But certainly not all open problems have to do with new physics. In many areas of physics, computing the implications of relatively simple laws becomes exceedingly difficult for many particles. Of historical importance is the classical three-body problem, describing the trajectory of 3 gravitational bodies such as the earth, moon and sun. The general case is not solved, despite developments over the last 300 years \cite{Musielak2014}.
In reality, the real challenge is to model the macroscopic properties of quantum many-body system with around $10^{23}$ particles. This broad field is called condensed matter physics and is important across many disciplines, including physics, chemistry, biology and engineering. Its practitioners include those who discover and develop new materials, those who seek to understand such materials at a fundamental level through experiments and theoretical analysis, and those who apply the materials to create new devices and technologies  \cite{Mora-Aznar2000}.
In computational chemistry, the many-body problem is tackled with methods which fall in one of the following categories: ab-initio methods, density functional theory (DFT), semi-empirical methods and large scale force-field methods \cite{Lewars2011}. The ab-initio methods such as (post-) Hartree-Fock methods are successful at calculating molecule geometries, molecule energies, thermodynamic properties, etc \cite{Lewars2011}.
Still, these methods are not fully able to capture all the properties of the so-called strongly correlated matter. ``A correlated electron problem is one in which interactions are so strong or have a character such that theories based on the underlying original `bare' particles fail even qualitatively to describe the material properties'' \cite{Alexandradinata2020}.
There exist different methods to investigate these exciting materials. A very limited number of models are quantum integrable, meaning that the ground state, the elementary excitations and various thermodynamic quantities can be computed exactly \cite{Lamers}. Also, some properties of models near criticality can be determined exactly with \Gls{CFT}. But for most systems, we can only simulate the behaviour with numerical techniques. To make progress, new fast and accurate numerical methods are needed, because exact diagonalisation becomes unfeasible for large systems. Some examples of such numerical techniques, which will not be discussed here, are: Dynamical Mean Field (DMFT) / Dynamical Cluster Approximation  (DCA), Series expansion, Density Matrix Embedding Theory (DMET), Fixed-node Monte Carlo, Diagrammatic Monte Carlo, Variational Monte Carlo, Functional renormalization group (FRG) and Coupled-cluster methods. \cite{Corboz}. In this thesis, a technique is proposed that builds on the broad field of \Glspl{TN}.
Strongly correlated electron systems host a tremendous variety of fascinating macroscopic phenomena including high-temperature superconductivity, quantum spin-liquids, fractionalized topological phases, and strange metals \cite{Alexandradinata2020}.

\section{Tensor networks}

One problem that makes simulation of large quantum systems difficult is the exponentially large size of the Hilbert space.  This is often referred to as the curse of dimensionality. But it turns out that Hilbert space of a many-body quantum system is far too large: all physical states, that is, all states that can ever be created, live on a tiny submanifold of measure zero \cite{Cirac}. The physical states obey the so called 'area law', which states that the entanglement of a system scales according to its area and not the volume. The physical quantum states are thus far less entangled than theoretically possible.  \Glspl{TN} automatically include this property, making them an efficient description of a quantum system.

%https://arxiv.org/pdf/2011.12127.pdf

\section{Outline thesis}

This master's thesis is organised as follows. \Cref{chap2} gives a practical introduction to \Glspl{TN}. Some important \Gls{TN} algorithms are discussed, including the \Gls{VUMPS} algorithm to contract infinite lattices. \Cref{chap3} treats phases of matter and criticality and some selected quantum models. The importance of operator exponentials is explained. \Cref{chap4} introduces the central topic of this thesis: \Gls{TN} cluster expansions to simulate operator exponentials. \Cref{chap5} treats the implementation aspects of the cluster expansions, in particular the numerical solvers. \Cref{chap:results} measures the accuracy of the cluster expansion in 1D and 2D. Also, some phase transitions of the 2D \Gls{TFI} model are calculated and compared with results from literature. \Cref{Chap7} summarises the main findings and gives an outlook for future work.