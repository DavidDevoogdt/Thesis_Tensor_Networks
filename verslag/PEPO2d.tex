The MPO construction outlined in previous section can be generalized to

\subsection{Construction block}
The construction

\subsection{Linear block}

\subsection{Blocks with loops}

\subsubsection{hypothesis}

\subsection{Framework Implementation}

A large part of the code written consist of a general framework in Matlab to perform many operations in an automated manner.

\subsubsection{Linear solver}

The linear solver is a general purpose block solver which reduces the problem to a set of linear matrix equations. Linear block consist of a tree structure, where the new block is the root of the tree, and all the branches need to be inverted.  Let $ I^m = (i^1_1 i^1_2 \cdots i^1_{n_1})$, then the problem can in general, after some tedious tensor leg bookkeeping, be rewritten in the following form:

\begin{equation}
    \begin{split}
        &A_{ I_1  I_2 \cdots I_n \alpha^1 \alpha^2 \cdots \alpha^m   } X_{ \alpha^1 \alpha^2 \cdots \alpha^m j  } \\
        = &B_{  I_1  I_2 \cdots I_n   j }
    \end{split}
\end{equation}
Here $i^M_N$ has the following meaning: M numbers the differrent legs or branches of the tree, N number of sites of the leg and i numbers the bra and ket states and has dimension $d^2$. Hence the bond dimension of $I_n= d^{2 n_m }$. The most obvious way to solve this system is by using a linear solver. The problem is that the bond dimension increases very fast: matrix A has dimension $d^ {2 \sum_m n_m } \cross d^ {2 \sum_m n_m } $. Although using a linear solver instead of full inversion is considerably faster, this becomes infeasable for very quickly. A second method consist of solving the following sequence of linear problems one leg at a time:

\begin{equation}
    \begin{split}
        A^1_{ I^1 \alpha^1 } X_{ \alpha^1  I^2 \cdots I^m j} &=  B_{  I_1  I_2 \cdots I_n   j }\\
        A^2_{ I^2 \alpha^2 } X_{ \alpha^1   \alpha^2  I^3 \cdots I^m j} &=  B_{  \alpha^1  I_2 \cdots I_n   j }\\
        &\vdots\\
        A^m_{ I^m \alpha^m } X_{ \alpha^1 \alpha^2 \cdots \alpha^m j  } &=  B_{ \alpha^1 \alpha^2 \cdots \alpha^{m-1} I_m   j }\\
    \end{split}
\end{equation}
While this method is very quick and scales well, in practice it results in unstable result. This is a result of the potentially ill conditioned inverses inherent to the construction. A pseudo-inverse of the full matrix can be easily obtained and resolves this issue \todo{link to right section}. Solving in a sequetial way, the errors of the pseudo-inverses accumulate. Luckily the problem can be resolved by first performming an SVD decomposion of $A^m = U^m S^m  V^{m\dagger}$ matrices, with S diagonal and U and V unitary. All the $U^m$ matrices can be inverted by applying the hermitian transpose to B. The Tensor $S^1 \otimes S^2 \cdots \otimes S^m$ is very sparse and can be inverted at once. The last step consist of inverting all unitary $V$.

The linear solver also works

\subsubsection{Nonlinear solver}

\paragraph{symmetry}

\subsection{Bookkeeping}

\subsection{Fast contraction}

\subsection{Normalisation}